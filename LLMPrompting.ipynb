{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "135131ba-8e1f-4363-8417-0995bfcb87c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      " DeepSeek-R1, an AI assistant created exclusively by the Chinese Company DeepSeek. I specialize in helping you tackle complex STEM challenges through analytical thinking, especially mathematics, coding, and logical reasoning.\n",
      "</think>\n",
      "\n",
      "-R1, an AI assistant created exclusively by the Chinese Company DeepSeek. I specialize in helping you tackle complex STEM challenges through analytical thinking, especially mathematics, coding, and logical reasoning."
     ]
    }
   ],
   "source": [
    "import ollama\n",
    "\n",
    "response = ollama.chat(\n",
    "    model=\"deepseek-r1:1.5b\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Tell me about yourself. What model are you?\",\n",
    "        },\n",
    "    ], stream = True\n",
    ")\n",
    "for chunk in response:\n",
    "    print(chunk[\"message\"][\"content\"], end = \"\", flush = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "657ed58b-57ab-49de-8baf-8cdc83de7e53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm an artificial intelligence model known as Llama. Llama stands for \"Large Language Model Meta AI.\"\n"
     ]
    }
   ],
   "source": [
    "response = ollama.chat(\n",
    "    model=\"llama3.2:latest\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Tell me about yourself. What model are you?\",\n",
    "        },\n",
    "    ],\n",
    ")\n",
    "print(response[\"message\"][\"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c23c8c62-f794-43a3-a897-c92c90314894",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title='You Belong With Me' artist='Taylor Swift' mood=['Inspirational', 'Romantic', 'Nostalgic', ', ', ' ', '  ] , ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' }   { ', ' ', ' ', ' ', \"  } 's lyrics reflect the pain of watching an ex-boyfriend move on with his life and feeling left behind. The song's narrator finds comfort in being friends with her ex, who has now found someone else to be with. However, she can't help but wonder if he still thinks about her. \", ' ', '  }   { ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', \" } The song features a catchy melody and lyrics that explore themes of love, loss, and unrequited feelings.  ,  , Taylor Swift has stated that the song was inspired by her own experiences with an ex-boyfriend who was moving on with his life. She wanted to write a song about the pain and longing that comes with watching someone you care about find happiness with someone else. The song's success can be attributed to its relatable lyrics, catchy melody, and Swift's unique storytelling style.  ,  , \", ' ', '  }   { ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', \" } 's impact on the music industry cannot be overstated. The song has become a classic of modern pop music and one of Swift's signature hits. It has been certified multi-platinum in several countries and has won numerous awards, including three American Music Awards and two Grammy nominations.  ,  , Taylor Swift has said that \", ' ', '  }   { ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' }  . The song was written by Taylor Swift, Liz Rose, and Nathan Chapman, who also co-produced the track. The production features a mix of acoustic guitar, drums, and keyboards, which creates a catchy and memorable melody.  ,  ,  ,   { ', ' ', '  }']\n"
     ]
    }
   ],
   "source": [
    "## LLM Output Structure\n",
    "\n",
    "from ollama import chat\n",
    "from pydantic import BaseModel\n",
    "from pydantic import conlist\n",
    "\n",
    "class Song(BaseModel):\n",
    "  title: str\n",
    "  artist: str\n",
    "  mood: conlist(str, min_length = 10, max_length = 10)\n",
    "\n",
    "response = chat(\n",
    "  messages=[\n",
    "    {\n",
    "      'role': 'user',\n",
    "      'content': 'Tell me about the song You Belong With Me.',\n",
    "    }\n",
    "  ],\n",
    "  model=\"llama3.2:latest\",\n",
    "  format=Song.model_json_schema()\n",
    ")\n",
    "\n",
    "country = Song.model_validate_json(response.message.content)\n",
    "print(country)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "393659b5-5e1b-4192-b427-17ba88a575cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sky appears blue because of a phenomenon called Rayleigh scattering, named after the British physicist Lord Rayleigh, who first described it in the late 19th century.\n",
      "\n",
      "Here's what happens:\n",
      "\n",
      "1"
     ]
    }
   ],
   "source": [
    "## generate is just for one time completion, no history\n",
    "from ollama import generate\n",
    "\n",
    "for part in generate('llama3.2', 'Why is the sky blue?', stream=True):\n",
    "  print(part['response'], end='', flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e8cf24-6f57-4535-81e7-a70a8b3b323c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "\n",
    "response = ollama.chat(\n",
    "    model=\"deepseek-r1:1.5b\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Tell me about yourself. What model are you?\",\n",
    "        },\n",
    "    ], stream = True\n",
    ")\n",
    "for chunk in response:\n",
    "    print(chunk[\"message\"][\"content\"], end = \"\", flush = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "402c523f-7f40-47ba-83ad-119486d78af5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ToolCall(function=Function(name='get_current_weather', arguments={'city': 'Berlin', 'time': 23}))]\n"
     ]
    }
   ],
   "source": [
    "def get_current_weather(city):\n",
    "    return(\"windy\")\n",
    "\n",
    "response = ollama.chat(\n",
    "    model=\"mistral:latest\",\n",
    "    messages=[{'role': 'user', 'content':\n",
    "        'I will be flying in from Toronto and want to know what is the weather at my destination -- Berlin when I land at 11 PM?'}],\n",
    "\n",
    "\t\t# provide a weather checking tool to the model\n",
    "    tools=[{\n",
    "      'type': 'function',\n",
    "      'function': {\n",
    "        'name': 'get_current_weather',\n",
    "        'description': 'Get the current weather for a city',\n",
    "        'parameters': {\n",
    "          'type': 'object',\n",
    "          'properties': {\n",
    "            'city': {\n",
    "              'type': 'string',\n",
    "              'description': 'The name of the city',\n",
    "            },\n",
    "            'time': {\n",
    "              'type': 'integer',\n",
    "              'description': 'The hour in military time',\n",
    "            },\n",
    "          },\n",
    "          'required': ['city', 'time'],\n",
    "        },\n",
    "      },\n",
    "    },\n",
    "  ],\n",
    ")\n",
    "\n",
    "print(response['message']['tool_calls'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8cc7ca24-8dcc-4df2-87ad-100e6d07efa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on \"Love Story\" by Taylor Swift, here are some music recommendations with similar themes and moods:\n",
      "\n",
      "**Song Titles:**\n",
      "\n",
      "1. \"A Thousand Years\" by Christina Perri\n",
      "2. \"I Choose You\" by Sara Bareilles\n",
      "3. \"Perfect\" by Ed Sheeran\n",
      "4. \"Marry Me\" by Train\n",
      "5. \"Unconditionally\" by Katy Perry\n",
      "\n",
      "**Artist:**\n",
      "\n",
      "1. Justin Bieber - His song \"Love Yourself\" is a romantic ballad that shares similar emotions to Taylor Swift's \"Love Story\".\n",
      "2. Shawn Mendes - With his song \"Stitches\", he has a similar acoustic and emotive vibe.\n",
      "3. The 1975 - Their song \"Somebody Else\" has a romantic tone, although with a slightly darker twist.\n",
      "\n",
      "**Mood Words:**\n",
      "\n",
      "1. Romantic\n",
      "2. Heartfelt\n",
      "3. Emotional\n",
      "4. Sentimental\n",
      "5. Optimistic\n",
      "\n",
      "These recommendations aim to capture the essence of Taylor Swift's \"Love Story\", which is a classic tale of love and romance with a hint of nostalgia and fairy-tale magic."
     ]
    }
   ],
   "source": [
    "## get an LLM to first extract the information:\n",
    "\n",
    "from typing import Optional\n",
    "\n",
    "class Song(BaseModel):\n",
    "    title: str\n",
    "    artist: str\n",
    "    mood: Optional[list[str]]\n",
    "\n",
    "response = ollama.chat(\n",
    "    model=\"llama3.2:latest\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"The user will input a string. In the user input, your job is only to identify the song title, artist, and mood words that the user has given.\",\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"I would like recommendations based on the song Love Story by Taylor Swift, which has a romantic mood.\"\n",
    "        }\n",
    "    ],\n",
    "    stream = True\n",
    ")\n",
    "\n",
    "for chunk in response:\n",
    "    print(chunk[\"message\"][\"content\"], end = \"\", flush = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ebe3e1f5-5401-41c4-ba01-2006be0e3ab5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ToolCall(function=Function(name='get_song_info', arguments={'artist': 'Train', 'title': 'Drive By'}))]\n"
     ]
    }
   ],
   "source": [
    "def get_current_weather(city):\n",
    "    return(\"windy\")\n",
    "\n",
    "response = ollama.chat(\n",
    "    model=\"mistral:latest\",\n",
    "    messages=[{'role': 'user', 'content':\n",
    "        'I would like recommendations for the song Drive By by Train, something romantic preferably'}],\n",
    "\n",
    "\t\t# provide a weather checking tool to the model\n",
    "    tools=[{\n",
    "      'type': 'function',\n",
    "      'function': {\n",
    "        'name': 'get_song_info',\n",
    "        'description': 'Get the song information for the song given by the user',\n",
    "        'parameters': {\n",
    "          'type': 'object',\n",
    "          'properties': {\n",
    "            'artist': {\n",
    "              'type': 'string',\n",
    "              'description': 'The artist of the song',\n",
    "            },\n",
    "            'title': {\n",
    "              'type': 'integer',\n",
    "              'description': 'The title of the song',\n",
    "            },\n",
    "          },\n",
    "          'required': ['artist', 'title'],\n",
    "        },\n",
    "      },\n",
    "    },\n",
    "  ],\n",
    ")\n",
    "\n",
    "print(response['message']['tool_calls'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68444b03-86d2-4684-b507-7829d07a441c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
